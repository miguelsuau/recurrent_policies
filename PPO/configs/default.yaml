parameters:
    total_steps: 2.0e+6
    num_workers: 8
    memory_size: 128
    batch_size: 32
    seq_len: 8
    rollout_steps: 8
    num_epoch: 3
    learning_rate: 2.5e-4
    beta: 1.0e-2
    epsilon: 0.2
    gamma: 0.99
    lambda: 0.95
    